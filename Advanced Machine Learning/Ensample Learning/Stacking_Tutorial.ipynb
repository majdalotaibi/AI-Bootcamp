{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dAL5_q1Iq6Tn"
      },
      "source": [
        "# Introduction\n",
        "Stacking, or Stacked Generalization, is an ensemble learning technique that combines multiple classification or regression models to improve predictive performance. In this tutorial, we will explore how to use stacking to predict diabetes onset based on the Pima Indians Diabetes dataset. This dataset includes diagnostic measurements for female patients of Pima Indian heritage, including features like glucose concentration, blood pressure, and BMI."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M9I2jfC4rDY_"
      },
      "source": [
        "## Steps"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f-lRPD4ErHNQ"
      },
      "source": [
        "### Step 1: Import Required Libraries\n",
        "First, import the necessary libraries for data manipulation, model training, and evaluation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "pkwPj7sJpT3-"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import StackingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uqSzo96rODW"
      },
      "source": [
        "### Step 2: Load and Preprocess the Dataset\n",
        "Load the Pima Indians Diabetes dataset and preprocess it. This includes handling missing values, encoding categorical variables using LabelEncoder, and scaling the features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "sbJcN_lJrYL3"
      },
      "outputs": [],
      "source": [
        "# Load the dataset\n",
        "url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.csv\"\n",
        "columns = ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age', 'Outcome']\n",
        "data = pd.read_csv(url, names=columns)\n",
        "\n",
        "# Handle missing values by replacing 0 with the mean (for columns where 0 is not a valid value)\n",
        "for col in ['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI']:\n",
        "    data[col] = data[col].replace(0, data[col].mean())\n",
        "\n",
        "# Encode categorical variables\n",
        "label_encoder = LabelEncoder()\n",
        "data['Outcome'] = label_encoder.fit_transform(data['Outcome'])\n",
        "\n",
        "# Split the data into features and target variable\n",
        "X = data.drop('Outcome', axis=1)\n",
        "y = data['Outcome']\n",
        "\n",
        "# Scale the features\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R1L2T1VFrc9N"
      },
      "source": [
        "### Step 3: Split the Dataset\n",
        "Split the dataset into training and testing sets to evaluate the performance of the models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "sp73xvZLrf6W"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=12)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z4UayTy7rohi"
      },
      "source": [
        "### Step 4: Initialize Base Models and the Meta-Model\n",
        "Initialize several base models and a meta-model. In this case, we will use a Decision Tree, a Support Vector Machine, a K-Nearest Neighbors classifier, and a Random Forest classifier as base models, and a Logistic Regression as the meta-model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Z7kngmX_rpat"
      },
      "outputs": [],
      "source": [
        "# Initialize base models\n",
        "base_models = [\n",
        "    ('decision_tree', DecisionTreeClassifier(random_state=42)),\n",
        "    ('svc', SVC(probability=True, random_state=42)),\n",
        "    ('knn', KNeighborsClassifier()),\n",
        "    ('random_forest', RandomForestClassifier(random_state=42))\n",
        "]\n",
        "\n",
        "# Initialize the meta-model\n",
        "meta_model = LogisticRegression()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KKSxJQqtrvkq"
      },
      "source": [
        "### Step 5: Initialize and Train the Stacking Classifier\n",
        "Create the StackingClassifier using the base models and the meta-model, and then train it on the training data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W2jCSfjWrwyM"
      },
      "outputs": [],
      "source": [
        "# Initialize the Stacking Classifier\n",
        "stacking_classifier = StackingClassifier(estimators=base_models, final_estimator=meta_model, cv=5)\n",
        "\n",
        "# Train the Stacking Classifier\n",
        "stacking_classifier.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D09KXIQDrzhL"
      },
      "source": [
        "### Step 6: Make Predictions\n",
        "Use the trained Stacking Classifier to make predictions on the test data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "SXsoNDSCr35O"
      },
      "outputs": [],
      "source": [
        "# Make predictions on the test data\n",
        "predictions = stacking_classifier.predict(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_vxnQpJr7Q_"
      },
      "source": [
        "### Step 7: Evaluate the Model\n",
        "Calculate the accuracy of the model based on its predictions and print the accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sQWRCZcdr-_c"
      },
      "outputs": [],
      "source": [
        "# Evaluate the model's accuracy\n",
        "accuracy = accuracy_score(y_test, predictions)\n",
        "print(f'Stacking Classifier Model Accuracy: {accuracy * 100:.2f}%')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
